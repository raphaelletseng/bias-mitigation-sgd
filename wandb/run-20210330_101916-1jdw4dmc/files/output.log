Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.
#=========================== Test data ==========================#
test_data:  <torch.utils.data.dataloader.DataLoader object at 0x00000209E935E208>
RegressionModel(
  (embs): ModuleList(
    (0): Embedding(8, 4)
    (1): Embedding(14, 7)
    (2): Embedding(8, 4)
    (3): Embedding(14, 7)
    (4): Embedding(7, 3)
    (5): Embedding(6, 3)
    (6): Embedding(3, 1)
    (7): Embedding(14, 7)
  )
  (lins): ModuleList(
    (0): Linear(in_features=40, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=250, bias=True)
  )
  (bns): ModuleList(
    (0): GroupNorm(1, 1000, eps=1e-05, affine=True)
    (1): GroupNorm(1, 500, eps=1e-05, affine=True)
    (2): GroupNorm(1, 250, eps=1e-05, affine=True)
  )
  (outp): Linear(in_features=250, out_features=1, bias=True)
  (emb_drop): Dropout(p=0.04, inplace=False)
  (drops): ModuleList(
    (0): Dropout(p=0.001, inplace=False)
    (1): Dropout(p=0.01, inplace=False)
    (2): Dropout(p=0.01, inplace=False)
  )
  (bn): GroupNorm(1, 4, eps=1e-05, affine=True)
  (activation): Sigmoid()
) 


=== RUN # 0 ====================================

  0%|                                           | 0/2 [00:00<?, ?it/s]CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  ..\c10\cuda\CUDAFunctions.cpp:100.)
 50%|█████████████████▌                 | 1/2 [00:01<00:01,  1.68s/it]grad and param do not obey the gradient layout contract. This is not an error, but may impair performance.
grad.sizes() = [3, 1], strides() = [1, 3]
param.sizes() = [3, 1], strides() = [1, 1] (Triggered internally at  ..\torch/csrc/autograd/functions/accumulate_grad.h:170.)
PrivacyEngine expected a batch of size 128 but the last step received a batch of size 98. This means that the privacy analysis will be a bit more pessimistic. You can set `drop_last = True` in your PyTorch dataloader to avoid this problem completely
100%|███████████████████████████████████| 2/2 [00:02<00:00,  1.33s/it]100%|███████████████████████████████████| 2/2 [00:02<00:00,  1.11s/it]
Train Epoch: 1 	Loss: 0.704593 (ε = 7.39, δ = 1e-05) for α = 4.4
  0%|                                           | 0/2 [00:00<?, ?it/s] 50%|█████████████████▌                 | 1/2 [00:00<00:00,  1.98it/s]100%|███████████████████████████████████| 2/2 [00:00<00:00,  2.10it/s]100%|███████████████████████████████████| 2/2 [00:00<00:00,  2.18it/s]
Train Epoch: 2 	Loss: 0.660489 (ε = 10.79, δ = 1e-05) for α = 3.4
  0%|                                           | 0/2 [00:00<?, ?it/s] 50%|█████████████████▌                 | 1/2 [00:00<00:00,  1.80it/s]100%|███████████████████████████████████| 2/2 [00:01<00:00,  1.89it/s]100%|███████████████████████████████████| 2/2 [00:01<00:00,  1.95it/s]
Train Epoch: 3 	Loss: 0.640462 (ε = 13.54, δ = 1e-05) for α = 3.0
  0%|                                           | 0/2 [00:00<?, ?it/s] 50%|█████████████████▌                 | 1/2 [00:00<00:00,  2.18it/s]100%|███████████████████████████████████| 2/2 [00:00<00:00,  2.11it/s]100%|███████████████████████████████████| 2/2 [00:00<00:00,  2.06it/s]
Train Epoch: 4 	Loss: 0.607478 (ε = 15.97, δ = 1e-05) for α = 2.7
  0%|                                           | 0/2 [00:00<?, ?it/s] 50%|█████████████████▌                 | 1/2 [00:00<00:00,  1.21it/s]100%|███████████████████████████████████| 2/2 [00:01<00:00,  1.34it/s]100%|███████████████████████████████████| 2/2 [00:01<00:00,  1.42it/s]
Train Epoch: 5 	Loss: 0.579260 (ε = 18.19, δ = 1e-05) for α = 2.5
  0%|                                           | 0/2 [00:00<?, ?it/s] 50%|█████████████████▌                 | 1/2 [00:00<00:00,  1.24it/s]100%|███████████████████████████████████| 2/2 [00:01<00:00,  1.34it/s]100%|███████████████████████████████████| 2/2 [00:01<00:00,  1.41it/s]
Train Epoch: 6 	Loss: 0.565487 (ε = 20.26, δ = 1e-05) for α = 2.4
  0%|                                           | 0/2 [00:00<?, ?it/s] 50%|█████████████████▌                 | 1/2 [00:00<00:00,  1.44it/s]100%|███████████████████████████████████| 2/2 [00:01<00:00,  1.50it/s]100%|███████████████████████████████████| 2/2 [00:01<00:00,  1.53it/s]
Train Epoch: 7 	Loss: 0.555156 (ε = 22.22, δ = 1e-05) for α = 2.3
  0%|                                           | 0/2 [00:00<?, ?it/s] 50%|█████████████████▌                 | 1/2 [00:00<00:00,  1.27it/s]100%|███████████████████████████████████| 2/2 [00:01<00:00,  1.40it/s]100%|███████████████████████████████████| 2/2 [00:01<00:00,  1.49it/s]
Train Epoch: 8 	Loss: 0.539739 (ε = 24.10, δ = 1e-05) for α = 2.2
  0%|                                           | 0/2 [00:00<?, ?it/s] 50%|█████████████████▌                 | 1/2 [00:00<00:00,  1.32it/s]100%|███████████████████████████████████| 2/2 [00:01<00:00,  1.44it/s]100%|███████████████████████████████████| 2/2 [00:01<00:00,  1.53it/s]
Train Epoch: 9 	Loss: 0.540873 (ε = 25.91, δ = 1e-05) for α = 2.2
  0%|                                           | 0/2 [00:00<?, ?it/s] 50%|█████████████████▌                 | 1/2 [00:00<00:00,  1.44it/s]100%|███████████████████████████████████| 2/2 [00:01<00:00,  1.39it/s]100%|███████████████████████████████████| 2/2 [00:01<00:00,  1.35it/s]
Train Epoch: 10 	Loss: 0.523535 (ε = 27.64, δ = 1e-05) for α = 2.1
  0%|                                           | 0/2 [00:00<?, ?it/s] 50%|█████████████████▌                 | 1/2 [00:00<00:00,  1.18it/s]100%|███████████████████████████████████| 2/2 [00:01<00:00,  1.15it/s]100%|███████████████████████████████████| 2/2 [00:01<00:00,  1.12it/s]
Train Epoch: 11 	Loss: 0.522968 (ε = 29.36, δ = 1e-05) for α = 2.1
  0%|                                           | 0/2 [00:00<?, ?it/s] 50%|█████████████████▌                 | 1/2 [00:00<00:00,  1.32it/s]100%|███████████████████████████████████| 2/2 [00:01<00:00,  1.43it/s]100%|███████████████████████████████████| 2/2 [00:01<00:00,  1.51it/s]
Train Epoch: 12 	Loss: 0.511252 (ε = 30.99, δ = 1e-05) for α = 2.0
  0%|                                           | 0/2 [00:00<?, ?it/s] 50%|█████████████████▌                 | 1/2 [00:00<00:00,  1.27it/s]100%|███████████████████████████████████| 2/2 [00:01<00:00,  1.37it/s]100%|███████████████████████████████████| 2/2 [00:01<00:00,  1.44it/s]
Train Epoch: 13 	Loss: 0.511159 (ε = 32.61, δ = 1e-05) for α = 2.0
  0%|                                           | 0/2 [00:00<?, ?it/s] 50%|█████████████████▌                 | 1/2 [00:00<00:00,  1.35it/s]100%|███████████████████████████████████| 2/2 [00:01<00:00,  1.44it/s]100%|███████████████████████████████████| 2/2 [00:01<00:00,  1.50it/s]
Train Epoch: 14 	Loss: 0.499896 (ε = 34.20, δ = 1e-05) for α = 1.9
  0%|                                           | 0/2 [00:00<?, ?it/s] 50%|█████████████████▌                 | 1/2 [00:00<00:00,  1.16it/s]100%|███████████████████████████████████| 2/2 [00:01<00:00,  1.17it/s]100%|███████████████████████████████████| 2/2 [00:01<00:00,  1.18it/s]
Train Epoch: 15 	Loss: 0.491951 (ε = 35.73, δ = 1e-05) for α = 1.9
  0%|                                           | 0/2 [00:00<?, ?it/s] 50%|█████████████████▌                 | 1/2 [00:01<00:01,  1.04s/it]100%|███████████████████████████████████| 2/2 [00:01<00:00,  1.05it/s]100%|███████████████████████████████████| 2/2 [00:01<00:00,  1.12it/s]
Train Epoch: 16 	Loss: 0.482433 (ε = 37.26, δ = 1e-05) for α = 1.9
  0%|                                           | 0/2 [00:00<?, ?it/s] 50%|█████████████████▌                 | 1/2 [00:01<00:01,  1.11s/it]100%|███████████████████████████████████| 2/2 [00:01<00:00,  1.02it/s]100%|███████████████████████████████████| 2/2 [00:01<00:00,  1.12it/s]
Train Epoch: 17 	Loss: 0.491532 (ε = 38.79, δ = 1e-05) for α = 1.9
  0%|                                           | 0/2 [00:00<?, ?it/s] 50%|█████████████████▌                 | 1/2 [00:00<00:00,  1.47it/s]100%|███████████████████████████████████| 2/2 [00:01<00:00,  1.56it/s]100%|███████████████████████████████████| 2/2 [00:01<00:00,  1.61it/s]
Train Epoch: 18 	Loss: 0.502326 (ε = 40.25, δ = 1e-05) for α = 1.8
  0%|                                           | 0/2 [00:00<?, ?it/s] 50%|█████████████████▌                 | 1/2 [00:00<00:00,  1.45it/s]100%|███████████████████████████████████| 2/2 [00:01<00:00,  1.56it/s]100%|███████████████████████████████████| 2/2 [00:01<00:00,  1.64it/s]
Train Epoch: 19 	Loss: 0.535422 (ε = 41.68, δ = 1e-05) for α = 1.8
  0%|                                           | 0/2 [00:00<?, ?it/s] 50%|█████████████████▌                 | 1/2 [00:00<00:00,  1.06it/s]100%|███████████████████████████████████| 2/2 [00:01<00:00,  1.11it/s]100%|███████████████████████████████████| 2/2 [00:01<00:00,  1.14it/s]
Train Epoch: 20 	Loss: 0.529253 (ε = 43.12, δ = 1e-05) for α = 1.8
size_average and reduce args will be deprecated, please use reduction='none' instead.
Traceback (most recent call last):
  File "main.py", line 328, in <module>
    main()
  File "main.py", line 265, in main
    fit = net.fit(X_cat, X_cont, y_true) #y labels) # X, y
  File "C:\Users\rapha\Documents\GitHub\bias-mitigation-sgd\model.py", line 108, in fit
    return super().fit(X, y)
  File "C:\Users\rapha\AppData\Local\Programs\Python\Python37\lib\site-packages\skorch\classifier.py", line 142, in fit
    return super(NeuralNetClassifier, self).fit(X, y, **fit_params)
  File "C:\Users\rapha\AppData\Local\Programs\Python\Python37\lib\site-packages\skorch\net.py", line 903, in fit
    self.partial_fit(X, y, **fit_params)
  File "C:\Users\rapha\AppData\Local\Programs\Python\Python37\lib\site-packages\skorch\net.py", line 862, in partial_fit
    self.fit_loop(X, y, **fit_params)
  File "C:\Users\rapha\AppData\Local\Programs\Python\Python37\lib\site-packages\skorch\net.py", line 776, in fit_loop
    step_fn=self.train_step, **fit_params)
  File "C:\Users\rapha\AppData\Local\Programs\Python\Python37\lib\site-packages\skorch\net.py", line 808, in run_single_epoch
    for data in self.get_iterator(dataset, training=training):
  File "C:\Users\rapha\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 435, in __next__
    data = self._next_data()
  File "C:\Users\rapha\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py", line 475, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "C:\Users\rapha\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\_utils\fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "C:\Users\rapha\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\_utils\fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "C:\Users\rapha\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataset.py", line 272, in __getitem__
    return self.dataset[self.indices[idx]]
  File "C:\Users\rapha\AppData\Local\Programs\Python\Python37\lib\site-packages\skorch\dataset.py", line 207, in __getitem__
    Xi = multi_indexing(X, i, self.X_indexing)
  File "C:\Users\rapha\AppData\Local\Programs\Python\Python37\lib\site-packages\skorch\utils.py", line 335, in multi_indexing
    return indexing(data, i)
  File "C:\Users\rapha\AppData\Local\Programs\Python\Python37\lib\site-packages\skorch\utils.py", line 201, in _indexing_dict
    return {k: v[i] for k, v in data.items()}
  File "C:\Users\rapha\AppData\Local\Programs\Python\Python37\lib\site-packages\skorch\utils.py", line 201, in <dictcomp>
    return {k: v[i] for k, v in data.items()}
IndexError: tuple index out of range
